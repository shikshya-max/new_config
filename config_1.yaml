model:
  d_fft: 1024
  d_model: 512
  dropout: 0.1
  heads: 4
  layers: 6
  type: transformer
paths:
  checkpoint_dir: checkpoints
  data_dir: datasets
preprocessing:
  char_repeats: 3
  languages:  
  - en-us
  lowercase: true
  n_val: 5000
  phoneme_symbols:
  - au
  - bha
  - aa
  - ra
  - na
  - ga
  - ah
  - ii
  - kha
  - pha
  - Ta
  - ha
  - chhya
  - sa
  - gyah
  - an
  - ahDa
  - tha
  - ba
  - sha
  - trah
  - e
  - Dha
  - Sa
  - da
  - nga
  - gha
  - ri
  - dha
  - Da
  - chha
  - pa
  - ma
  - ya
  - aah
  - la
  - i
  - wa
  - ai
  - ja
  - cha
  - jha
  - oo
  - ka
  - u
  - o
  - ta
  - Tha
  text_symbols: "अआइईउऊएऐओऔऋअंअःकखगघङचछजझञटठडढणतथदधनपफबभमयरलवशषसहक्षत्रज्ञ"
training:
  batch_size: 32
  batch_size_val: 32
  checkpoint_steps: 100000
  epochs: 50
  generate_steps: 500
  learning_rate: 0.0001
  n_generate_samples: 10
  scheduler_plateau_factor: 0.5
  scheduler_plateau_patience: 10
  store_phoneme_dict_in_model: true
  test_steps: 500
  validate_steps: 500
  warmup_steps: 100
